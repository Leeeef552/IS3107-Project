# =====================================================================
# DATABASE CONFIGURATION
# =====================================================================
# TimescaleDB (PostgreSQL) connection settings for time-series data storage
TIMESCALE_HOST=timescaledb
TIMESCALE_PORT=5432
TIMESCALE_USER=postgres
TIMESCALE_PASSWORD=pass
TIMESCALE_DBNAME=postgres

# =====================================================================
# KAGGLE API KEYS
# =====================================================================
# Required to download datasets programmatically via Kaggle API
# Register at: https://www.kaggle.com/settings/account

KAGGLE_USERNAME=leeeefun
KAGGLE_KEY=your_kaggle_api_key_here

# =====================================================================
# NEWS & SENTIMENT ANALYSIS API KEYS
# =====================================================================

# NewsAPI – https://newsapi.org/register
# Free tier: 100 requests/day, max 1 month of historical data
# Used for: Daily/weekly/monthly sentiment (not hourly due to limits)
# Note: System enforces 30-day window to comply with free tier

# CryptoCompare – https://www.cryptocompare.com/cryptopian/api-keys
# Free tier: ~100,000 calls/month (requires email activation)
# Used for: Hourly, daily, weekly, and monthly crypto sentiment & pricing

# Reddit API – https://www.reddit.com/prefs/apps
# Create a "script"-type app to get credentials (free, no approval needed)
# Format for USER_AGENT: <app_name>/<version> by /u/<reddit_username>

# Alpha Vantage – https://www.alphavantage.co/support/#api-key
# Free tier: 25 requests/day (lifetime key if legitimate email used)
# Primarily used for historical financial news & macro indicators
# Tip: Use test@company.com if testing, but real email is recommended


NEWS_API_KEY=your_newsapi_key_here
CRYPTOCOMPARE_API_KEY=your_cryptocompare_key_here
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret
REDDIT_USER_AGENT=BitcoinSentimentBot/1.0
ALPHA_VANTAGE_API_KEY=your_alphavantage_api_key

# =====================================================================
# LOCAL DIRECTORY AND FILEPATHS FOR AIRFLOW
# =====================================================================
# Mounted paths inside Airflow containers for data persistence

DATA_DIR=/opt/historical_data          # Raw and fetched data
SCHEMA_DIR=/opt/schema                 # Schema definitions (e.g., JSON, Avro)
AGGREGATES_DIR=/opt/aggregates         # Aggregated features (e.g., OHLCV + sentiment)
TRAINING_DIR=/opt/training             # Model training artifacts & logs
PREDICTION_DIR=/opt/prediction         # Inference outputs & forecasts

# =====================================================================
# AIRFLOW CONFIGURATION
# =====================================================================

AIRFLOW_UID=50000
AIRFLOW_GID=0